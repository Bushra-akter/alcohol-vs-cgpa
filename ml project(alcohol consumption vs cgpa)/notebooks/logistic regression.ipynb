{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "The data for this data science project in researching factors influencing teenage alcoholism was sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/student%2Bperformance#). It was donated to the site by Prof. Paulo Cortez of University Minho. His original work on the dataset, \"USING DATA MINING TO PREDICT SECONDARY SCHOOL STUDENT PERFORMANCE, can be found [here](http://www3.dsi.uminho.pt/pcortez/student.pdf)\n",
    "\n",
    "The data set consists of information on various attributes for each student, taking Portuguese language classes who come from ether of the two higher secondary schools, The Gabriel Pereira School and  the Mousinho da Silveira School. There is information on 649 students on 33 attributes. A list of all the features with description can be found on [Readme](https://github.com/Yeshi341/Student_Alcohol_Consumption/blob/master/Readme.md) section of the Github page to this project. The features have also been described sequentially as [EDA]('EDA.ipynb') was performed on each variable in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessing_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>paid</th>\n",
       "      <th>activities</th>\n",
       "      <th>nursery</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>absences</th>\n",
       "      <th>alc</th>\n",
       "      <th>stability</th>\n",
       "      <th>academic_support</th>\n",
       "      <th>idle</th>\n",
       "      <th>grade_avg</th>\n",
       "      <th>delinquency</th>\n",
       "      <th>Medu_1</th>\n",
       "      <th>Medu_2</th>\n",
       "      <th>Medu_3</th>\n",
       "      <th>Medu_4</th>\n",
       "      <th>Fedu_1</th>\n",
       "      <th>Fedu_2</th>\n",
       "      <th>Fedu_3</th>\n",
       "      <th>Fedu_4</th>\n",
       "      <th>Mjob_2</th>\n",
       "      <th>Mjob_3</th>\n",
       "      <th>Mjob_4</th>\n",
       "      <th>Mjob_5</th>\n",
       "      <th>Fjob_2</th>\n",
       "      <th>Fjob_3</th>\n",
       "      <th>Fjob_4</th>\n",
       "      <th>Fjob_5</th>\n",
       "      <th>reason_2</th>\n",
       "      <th>reason_3</th>\n",
       "      <th>reason_4</th>\n",
       "      <th>guardian_2</th>\n",
       "      <th>guardian_3</th>\n",
       "      <th>traveltime_2</th>\n",
       "      <th>traveltime_3</th>\n",
       "      <th>traveltime_4</th>\n",
       "      <th>studytime_2</th>\n",
       "      <th>studytime_3</th>\n",
       "      <th>studytime_4</th>\n",
       "      <th>failures_1</th>\n",
       "      <th>failures_2</th>\n",
       "      <th>failures_3</th>\n",
       "      <th>health_2</th>\n",
       "      <th>health_3</th>\n",
       "      <th>health_4</th>\n",
       "      <th>health_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  Pstatus  paid  activities  nursery  internet  \\\n",
       "0       1    1   18        0        0     0           0        1         0   \n",
       "1       1    1   17        0        1     0           0        0         1   \n",
       "2       1    1   15        0        1     0           0        1         1   \n",
       "3       1    1   15        0        1     0           1        1         1   \n",
       "4       1    1   16        0        1     0           0        1         0   \n",
       "\n",
       "   romantic  absences  alc  stability  academic_support  idle  grade_avg  \\\n",
       "0         0         4    0          4                 2    12       7.33   \n",
       "1         0         2    0          5                 2     9      10.33   \n",
       "2         0         6    0          0                 2     6      12.33   \n",
       "3         1         0    0          3                 2     4      14.00   \n",
       "4         0         0    0          4                 2     6      12.33   \n",
       "\n",
       "   delinquency  Medu_1  Medu_2  Medu_3  Medu_4  Fedu_1  Fedu_2  Fedu_3  \\\n",
       "0            0       0       0       0       1       0       0       0   \n",
       "1            0       1       0       0       0       1       0       0   \n",
       "2            0       1       0       0       0       1       0       0   \n",
       "3            0       0       0       0       1       0       1       0   \n",
       "4            0       0       0       1       0       0       0       1   \n",
       "\n",
       "   Fedu_4  Mjob_2  Mjob_3  Mjob_4  Mjob_5  Fjob_2  Fjob_3  Fjob_4  Fjob_5  \\\n",
       "0       1       0       0       0       0       0       1       0       0   \n",
       "1       0       0       0       0       0       0       0       0       1   \n",
       "2       0       0       0       0       0       0       0       0       1   \n",
       "3       0       0       0       1       0       1       0       0       0   \n",
       "4       0       0       0       0       1       0       0       0       1   \n",
       "\n",
       "   reason_2  reason_3  reason_4  guardian_2  guardian_3  traveltime_2  \\\n",
       "0         0         1         0           1           0             1   \n",
       "1         0         1         0           0           0             0   \n",
       "2         0         0         1           1           0             0   \n",
       "3         0         0         0           1           0             0   \n",
       "4         0         0         0           0           0             0   \n",
       "\n",
       "   traveltime_3  traveltime_4  studytime_2  studytime_3  studytime_4  \\\n",
       "0             0             0            1            0            0   \n",
       "1             0             0            1            0            0   \n",
       "2             0             0            1            0            0   \n",
       "3             0             0            0            1            0   \n",
       "4             0             0            1            0            0   \n",
       "\n",
       "   failures_1  failures_2  failures_3  health_2  health_3  health_4  health_5  \n",
       "0           0           0           0         0         1         0         0  \n",
       "1           0           0           0         0         1         0         0  \n",
       "2           0           0           0         0         1         0         0  \n",
       "3           0           0           0         0         0         0         1  \n",
       "4           0           0           0         0         0         0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 51)\n",
      "Index(['school', 'sex', 'age', 'address', 'Pstatus', 'paid', 'activities',\n",
      "       'nursery', 'internet', 'romantic', 'absences', 'alc', 'stability',\n",
      "       'academic_support', 'idle', 'grade_avg', 'delinquency', 'Medu_1',\n",
      "       'Medu_2', 'Medu_3', 'Medu_4', 'Fedu_1', 'Fedu_2', 'Fedu_3', 'Fedu_4',\n",
      "       'Mjob_2', 'Mjob_3', 'Mjob_4', 'Mjob_5', 'Fjob_2', 'Fjob_3', 'Fjob_4',\n",
      "       'Fjob_5', 'reason_2', 'reason_3', 'reason_4', 'guardian_2',\n",
      "       'guardian_3', 'traveltime_2', 'traveltime_3', 'traveltime_4',\n",
      "       'studytime_2', 'studytime_3', 'studytime_4', 'failures_1', 'failures_2',\n",
      "       'failures_3', 'health_2', 'health_3', 'health_4', 'health_5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data and features : (649, 51) \n",
      "\n",
      "features are: Index(['school', 'sex', 'age', 'address', 'Pstatus', 'paid', 'activities',\n",
      "       'nursery', 'internet', 'romantic', 'absences', 'alc', 'stability',\n",
      "       'academic_support', 'idle', 'grade_avg', 'delinquency', 'Medu_1',\n",
      "       'Medu_2', 'Medu_3', 'Medu_4', 'Fedu_1', 'Fedu_2', 'Fedu_3', 'Fedu_4',\n",
      "       'Mjob_2', 'Mjob_3', 'Mjob_4', 'Mjob_5', 'Fjob_2', 'Fjob_3', 'Fjob_4',\n",
      "       'Fjob_5', 'reason_2', 'reason_3', 'reason_4', 'guardian_2',\n",
      "       'guardian_3', 'traveltime_2', 'traveltime_3', 'traveltime_4',\n",
      "       'studytime_2', 'studytime_3', 'studytime_4', 'failures_1', 'failures_2',\n",
      "       'failures_3', 'health_2', 'health_3', 'health_4', 'health_5'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('data and features :', df.shape,'\\n' ) \n",
    "print('features are:', df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Features:  (519, 50) Target:  (519,)\n",
      "Test set - Features:  (130, 50) Target:  (130,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns = ['alc'], axis = 1) \n",
    "y = df['alc']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=150, test_size=0.2)\n",
    "\n",
    "print(\"Training set - Features: \", X_train.shape, \"Target: \", y_train.shape,)\n",
    "print(\"Test set - Features: \", X_test.shape, \"Target: \",y_test.shape,)\n",
    "#print(y_train.value_counts(normalize = True))\n",
    "#print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance - with Oversampling minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling Minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training  = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light drinker count: 426\n",
      "heavy drinker count: 93\n"
     ]
    }
   ],
   "source": [
    "light_drinker = training[training.alc==0]\n",
    "heavy_drinker = training[training.alc==1]\n",
    "\n",
    "print('light drinker count: '+ str(len(light_drinker)))\n",
    "print('heavy drinker count: '+ str(len(heavy_drinker)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 51)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heavy_drinker_upsampled = resample(heavy_drinker,\n",
    "                          replace=True, \n",
    "                          n_samples=len(light_drinker), \n",
    "                          random_state=23) \n",
    "heavy_drinker_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    426\n",
       "1    426\n",
       "Name: alc, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled = pd.concat([light_drinker, heavy_drinker_upsampled])\n",
    "upsampled.alc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 50)\n"
     ]
    }
   ],
   "source": [
    "y_train_up = upsampled.alc\n",
    "X_train_up = upsampled.drop(columns = 'alc', axis=1)\n",
    "print(X_train_up.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= MinMaxScaler()  \n",
    "scaler.fit(X_train_up)\n",
    "\n",
    "X_train_scaleu = scaler.transform(X_train_up)  \n",
    "X_test_scale = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'address', 'absences', 'academic_support', 'idle',\n",
      "       'grade_avg', 'reason_4', 'studytime_2', 'studytime_3'],\n",
      "      dtype='object') Index(['sex', 'age', 'address', 'absences', 'academic_support', 'idle',\n",
      "       'grade_avg', 'reason_4', 'studytime_2', 'studytime_3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=10) \n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "\n",
    "X_train_kb10 = X_train_up[selected_columns]\n",
    "X_test_kb10 = X_test[selected_columns]\n",
    "print(X_train_kb10.columns, X_test_kb10.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=15) \n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "removed_columns = X_train_up.columns[~selector.get_support()]\n",
    "\n",
    "X_train_kb15 = X_train_up[selected_columns]\n",
    "X_test_kb15 = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=20) \n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "removed_columns = X_train_up.columns[~selector.get_support()]\n",
    "\n",
    "X_train_kb20 = X_train_up[selected_columns]\n",
    "X_test_kb20 = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=25)\n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "removed_columns = X_train_up.columns[~selector.get_support()]\n",
    "\n",
    "X_train_kb25 = X_train_up[selected_columns]\n",
    "X_test_kb25 = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=30)\n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "removed_columns = X_train_up.columns[~selector.get_support()]\n",
    "\n",
    "X_train_kb30 = X_train_up[selected_columns]\n",
    "X_test_kb30 = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Kbest 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=35) \n",
    "selector.fit(X_train_up, y_train_up)\n",
    "\n",
    "selected_columns = X_train_up.columns[selector.get_support()]\n",
    "removed_columns = X_train_up.columns[~selector.get_support()]\n",
    "\n",
    "X_train_kb35 = X_train_up[selected_columns]\n",
    "X_test_kb35 = X_test[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable in this project, tells whether a student is a heavy alcohol drinker or not. Our main concern here becomes that we do not want to predict that a student is not a heavy drinker when they actually are. Thus, we are interested in minimizing chances of any False Negatives. Correctly, identifying student has a problem allows us to appropriately allocate help or resources to ameliorate conditions for that student/s to minimize any drinking problem. \n",
    "\n",
    "Thus, our focus will be on the recall score or sensitivity score that tells us the proportion of actual positives identified correctly, given by (TP/(TP+FN). The higher this score, the better. \n",
    "\n",
    "We also looked at the Accuracy score and the F1 scores as extra metrics to compare model performance on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Logistic Model\n",
    "**Running a model without any class imbalance resolution on the original features with no transformations or scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[98  5]\n",
      " [20  7]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       103\n",
      "           1       0.58      0.26      0.36        27\n",
      "\n",
      "    accuracy                           0.81       130\n",
      "   macro avg       0.71      0.61      0.62       130\n",
      "weighted avg       0.78      0.81      0.78       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(solver='liblinear', random_state=150)\n",
    "\n",
    "lr1.fit(X_train, y_train)\n",
    "p = lr1.predict(X_test)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "results['1.logistic_original_features'] = (round(metrics.accuracy_score(y_test, p),4), \n",
    "                            round(metrics.f1_score(y_test, p),4), \n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression with X_train_up (Upsampled Unscaled Train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[87 16]\n",
      " [14 13]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       103\n",
      "           1       0.45      0.48      0.46        27\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.65      0.66      0.66       130\n",
      "weighted avg       0.78      0.77      0.77       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_u = LogisticRegression(solver='liblinear')\n",
    "lr_u.fit(X_train_up, y_train_up)\n",
    "\n",
    "\n",
    "p = lr_u.predict(X_test)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['2.lr_upsampled'] = (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression with X_train_up (Upsampled and Scaled Train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[90 13]\n",
      " [15 12]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       103\n",
      "           1       0.48      0.44      0.46        27\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.67      0.66      0.66       130\n",
      "weighted avg       0.78      0.78      0.78       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_us = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "lr_us.fit(X_train_scaleu, y_train_up)\n",
    "p = lr_us.predict(X_test_scale)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['3.lr_upscaled'] = (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression with K best 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[84 19]\n",
      " [11 16]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       103\n",
      "           1       0.46      0.59      0.52        27\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.67      0.70      0.68       130\n",
      "weighted avg       0.80      0.77      0.78       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb10_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "kb10_lr.fit(X_train_kb10, y_train_up)\n",
    "p = kb10_lr.predict(X_test_kb10)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926)}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['4.lr_kb10'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression with K best 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[85 18]\n",
      " [11 16]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.85       103\n",
      "           1       0.47      0.59      0.52        27\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.68      0.71      0.69       130\n",
      "weighted avg       0.80      0.78      0.79       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb15_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "kb15_lr.fit(X_train_kb15, y_train_up)\n",
    "p = kb15_lr.predict(X_test_kb15)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926),\n",
       " '5.lr_kb15': (0.7769, 0.5246, 0.5926)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['5.lr_kb15'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Logistic Regression with K best 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[85 18]\n",
      " [11 16]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.85       103\n",
      "           1       0.47      0.59      0.52        27\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.68      0.71      0.69       130\n",
      "weighted avg       0.80      0.78      0.79       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb20_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "kb20_lr.fit(X_train_kb20, y_train_up)\n",
    "p = kb20_lr.predict(X_test_kb20)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926),\n",
       " '5.lr_kb15': (0.7769, 0.5246, 0.5926),\n",
       " '6.lr_kb20': (0.7769, 0.5246, 0.5926)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['6.lr_kb20'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Logistic Regression with K best 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[86 17]\n",
      " [11 16]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       103\n",
      "           1       0.48      0.59      0.53        27\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.69      0.71      0.70       130\n",
      "weighted avg       0.80      0.78      0.79       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb25_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "kb25_lr.fit(X_train_kb25, y_train_up)\n",
    "p= kb25_lr.predict(X_test_kb25)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926),\n",
       " '5.lr_kb15': (0.7769, 0.5246, 0.5926),\n",
       " '6.lr_kb20': (0.7769, 0.5246, 0.5926),\n",
       " '7.lr_kb25': (0.7846, 0.5333, 0.5926)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['7.lr_kb25'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Logistic Regression with K best 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[87 16]\n",
      " [13 14]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       103\n",
      "           1       0.47      0.52      0.49        27\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.67      0.68      0.67       130\n",
      "weighted avg       0.79      0.78      0.78       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb30_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "kb30_lr.fit(X_train_kb30, y_train_up)\n",
    "p = kb30_lr.predict(X_test_kb30)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926),\n",
       " '5.lr_kb15': (0.7769, 0.5246, 0.5926),\n",
       " '6.lr_kb20': (0.7769, 0.5246, 0.5926),\n",
       " '7.lr_kb25': (0.7846, 0.5333, 0.5926),\n",
       " '8.lr_kb30': (0.7769, 0.4912, 0.5185)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['8.lr_kb30'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Logistic Regression with K best 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[86 17]\n",
      " [13 14]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       103\n",
      "           1       0.45      0.52      0.48        27\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.66      0.68      0.67       130\n",
      "weighted avg       0.78      0.77      0.77       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kb35_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "kb35_lr.fit(X_train_kb35, y_train_up)\n",
    "p = kb35_lr.predict(X_test_kb35)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1.logistic_original_features': (0.8077, 0.359, 0.2593),\n",
       " '2.lr_upsampled': (0.7692, 0.4643, 0.4815),\n",
       " '3.lr_upscaled': (0.7846, 0.4615, 0.4444),\n",
       " '4.lr_kb10': (0.7692, 0.5161, 0.5926),\n",
       " '5.lr_kb15': (0.7769, 0.5246, 0.5926),\n",
       " '6.lr_kb20': (0.7769, 0.5246, 0.5926),\n",
       " '7.lr_kb25': (0.7846, 0.5333, 0.5926),\n",
       " '8.lr_kb30': (0.7769, 0.4912, 0.5185),\n",
       " '9.lr_kb35': (0.7692, 0.4828, 0.5185)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['9.lr_kb35'] =  (round(metrics.accuracy_score(y_test, p),4), \n",
    "                           round(metrics.f1_score(y_test, p),4),\n",
    "                          round(metrics.recall_score(y_test, p),4))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final model**\n",
    "we see that higher accuracy come from knn_kb10 so we featured 10 variables for KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "confusion matrix\n",
      "\n",
      "[[84 19]\n",
      " [11 16]]\n",
      "\n",
      "\n",
      "classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       103\n",
      "           1       0.46      0.59      0.52        27\n",
      "\n",
      "    accuracy                           0.77       130\n",
      "   macro avg       0.67      0.70      0.68       130\n",
      "weighted avg       0.80      0.77      0.78       130\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "kb10_lr.fit(X_train_kb10, y_train_up)\n",
    "p = kb10_lr.predict(X_test_kb10)\n",
    "\n",
    "print('\\n\\nconfusion matrix\\n')\n",
    "print(confusion_matrix(y_test,p))\n",
    "print('\\n\\nclassification Report\\n')\n",
    "print(classification_report(y_test,p))\n",
    "\n",
    "cm = confusion_matrix(y_test, p)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
